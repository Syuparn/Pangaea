// Code generated by goyacc -o ./parser/y.go -v ./parser/y.output ./parser/parser.go.y. DO NOT EDIT.

//line ./parser/parser.go.y:1

package parser

import __yyfmt__ "fmt"

//line ./parser/parser.go.y:4

import (
	"bytes"
	"errors"
	"fmt"
	"io"
	"math"
	"sort"
	"strconv"
	"strings"

	"github.com/macrat/simplexer"

	"github.com/Syuparn/pangaea/ast"
)

//line ./parser/parser.go.y:22
type yySymType struct {
	yys               int
	token             *simplexer.Token
	recvAndChain      *ast.RecvAndChain
	chain             *ast.Chain
	ident             *ast.Ident
	expr              ast.Expr
	funcComponent     ast.FuncComponent
	funcComponentList []*ast.FuncComponent
	argList           *ast.ArgList
	exprList          []ast.Expr
	pair              *ast.Pair
	pairList          []*ast.Pair
	kwargPair         *ast.KwargPair
	formerStrPiece    *ast.FormerStrPiece
	stmt              ast.Stmt
	stmts             []ast.Stmt
	program           *ast.Program
}

const INT = 57346
const FLOAT = 57347
const HEX_INT = 57348
const BIN_INT = 57349
const OCT_INT = 57350
const EXP_FLOAT = 57351
const EXP_INT = 57352
const SYMBOL = 57353
const CHAR_STR = 57354
const BACKQUOTE_STR = 57355
const DOUBLEQUOTE_STR = 57356
const HEAD_STR_PIECE = 57357
const MID_STR_PIECE = 57358
const TAIL_STR_PIECE = 57359
const DOUBLE_STAR = 57360
const PLUS = 57361
const MINUS = 57362
const STAR = 57363
const SLASH = 57364
const BANG = 57365
const DOUBLE_SLASH = 57366
const PERCENT = 57367
const SPACESHIP = 57368
const EQ = 57369
const NEQ = 57370
const TOPIC_EQ = 57371
const TOPIC_NEQ = 57372
const LT = 57373
const LE = 57374
const GT = 57375
const GE = 57376
const BIT_LSHIFT = 57377
const BIT_RSHIFT = 57378
const BIT_AND = 57379
const BIT_OR = 57380
const BIT_XOR = 57381
const BIT_NOT = 57382
const AND = 57383
const OR = 57384
const IADD = 57385
const ISUB = 57386
const ADD_CHAIN = 57387
const MAIN_CHAIN = 57388
const MULTILINE_ADD_CHAIN = 57389
const MULTILINE_MAIN_CHAIN = 57390
const IDENT = 57391
const PRIVATE_IDENT = 57392
const ARG_IDENT = 57393
const KWARG_IDENT = 57394
const LPAREN = 57395
const RPAREN = 57396
const COMMA = 57397
const COLON = 57398
const LBRACE = 57399
const RBRACE = 57400
const VERT = 57401
const LBRACKET = 57402
const RBRACKET = 57403
const CARET = 57404
const MAP_LBRACE = 57405
const METHOD_MAP_LBRACE = 57406
const METHOD_LBRACE = 57407
const LITER = 57408
const RITER = 57409
const METHOD_LITER = 57410
const DIAMOND = 57411
const RET = 57412
const SEMICOLON = 57413
const ASSIGN = 57414
const COMPOUND_ASSIGN = 57415
const RIGHT_ASSIGN = 57416
const IF = 57417
const ELSE = 57418
const RETURN = 57419
const RAISE = 57420
const YIELD = 57421
const DEFER = 57422
const JUMP = 57423
const JUMPIF = 57424
const UNARY_OP = 57425
const CALLING = 57426
const GROUPING = 57427
const INDEXING = 57428

var yyToknames = [...]string{
	"$end",
	"error",
	"$unk",
	"INT",
	"FLOAT",
	"HEX_INT",
	"BIN_INT",
	"OCT_INT",
	"EXP_FLOAT",
	"EXP_INT",
	"SYMBOL",
	"CHAR_STR",
	"BACKQUOTE_STR",
	"DOUBLEQUOTE_STR",
	"HEAD_STR_PIECE",
	"MID_STR_PIECE",
	"TAIL_STR_PIECE",
	"DOUBLE_STAR",
	"PLUS",
	"MINUS",
	"STAR",
	"SLASH",
	"BANG",
	"DOUBLE_SLASH",
	"PERCENT",
	"SPACESHIP",
	"EQ",
	"NEQ",
	"TOPIC_EQ",
	"TOPIC_NEQ",
	"LT",
	"LE",
	"GT",
	"GE",
	"BIT_LSHIFT",
	"BIT_RSHIFT",
	"BIT_AND",
	"BIT_OR",
	"BIT_XOR",
	"BIT_NOT",
	"AND",
	"OR",
	"IADD",
	"ISUB",
	"ADD_CHAIN",
	"MAIN_CHAIN",
	"MULTILINE_ADD_CHAIN",
	"MULTILINE_MAIN_CHAIN",
	"IDENT",
	"PRIVATE_IDENT",
	"ARG_IDENT",
	"KWARG_IDENT",
	"LPAREN",
	"RPAREN",
	"COMMA",
	"COLON",
	"LBRACE",
	"RBRACE",
	"VERT",
	"LBRACKET",
	"RBRACKET",
	"CARET",
	"MAP_LBRACE",
	"METHOD_MAP_LBRACE",
	"METHOD_LBRACE",
	"LITER",
	"RITER",
	"METHOD_LITER",
	"DIAMOND",
	"RET",
	"SEMICOLON",
	"ASSIGN",
	"COMPOUND_ASSIGN",
	"RIGHT_ASSIGN",
	"IF",
	"ELSE",
	"RETURN",
	"RAISE",
	"YIELD",
	"DEFER",
	"JUMP",
	"JUMPIF",
	"UNARY_OP",
	"CALLING",
	"GROUPING",
	"INDEXING",
}

var yyStatenames = [...]string{}

const yyEofCode = 1
const yyErrCode = 2
const yyInitialStackSize = 16

//line ./parser/parser.go.y:2104

func Parse(src io.Reader) (*ast.Program, error) {
	lexer := NewLexer(src)
	prog, err := tryParse(src, lexer)

	if err != nil {
		return nil, err
	}

	if prog == nil {
		return nil, errors.New("failed to parse")
	}

	program, ok := prog.(*ast.Program)
	if !ok {
		msg := fmt.Sprintf("could not parsed to *ast.Program. got=%+v", program)
		return nil, errors.New(msg)
	}

	return program, nil
}

func tryParse(src io.Reader, l *Lexer) (a ast.Node, e error) {
	// HACK: catch yyParse error by recover
	// (because yacc cannot return error)
	defer func(l *Lexer) {
		if err := recover(); err != nil {
			m := "error occured:"
			if l.Source != nil {
				m = fmt.Sprintf("%s\n%s", m,
					l.ErrMsg())
			} else {
				m = m + "\nbefore lexing"
			}
			e = errors.New(m)
		}
	}(l)

	yyParse(l)
	return l.program, nil
}

type Lexer struct {
	lexer *simplexer.Lexer
	// NOTE: embed final ast in lexer because yyParse cannot return ast
	program ast.Node
	Source  *ast.Source
	curRule string
}

func tokenTypes() []simplexer.TokenType {
	// NOTE: make operators map to generate symbol regex easily
	// (for operator symbol such as '+ or '<=>)
	methodOps := map[string]string{
		"spaceship":  `<=>`,
		"eq":         `==`,
		"neq":        `!=`,
		"topicEq":    `===`,
		"topicNeq":   `!==`,
		"ge":         `>=`,
		"le":         `<=`,
		"gt":         `>`,
		"lt":         `<`,
		"bitLShift":  `<<`,
		"bitRShift":  `>>`,
		"bitAnd":     `/&`,
		"bitOr":      `/\|`,
		"bitXor":     `/\^`,
		"bitNot":     `/~`,
		"bang":       `!`,
		"plus":       `\+`,
		"minus":      `\-`,
		"star":       `\*`,
		"doubleStar": `\*\*`,
		"slash":      `/`,
		// NOTE: Do not use backquote! (otherwise commented out)
		"doubleSlash": "//",
		"percent":     `%`,
		"iAdd":        `\+%`,
		"iSub":        `\-%`,
	}

	// NOTE: unary and comparison ops cannot be used for compound assign
	// `&&` and `||` are not methodops but can be used for compound assign
	compoundAssign := `(<<|>>|/&|/\||/\^|\+|\-|\*|\*\*|/|//|%|&&|\|\|)=`

	ident := `[a-zA-Z][a-zA-Z0-9_]*[!?]?`
	// NOTE: comment(, which starts with "#") is included in RET
	// `#[^\n\r]*` is neseccery to lex final line comment (i.e. `#`)
	comment := `#[^\n\r]*`
	retChar := `(\r|\n|\r\n)`
	ret := fmt.Sprintf(`(([ \t]*(%s)?%s)+|%s)`, comment, retChar, comment)

	// NOTE: lexer deals with multiline chain
	// (if parser does, shift/reduce conflict occurs)
	keepChainRet := fmt.Sprintf(`([ \t]*(%s)?%s)+[ \t]*\|`, comment, retChar)

	methodOpTokens := []string{}
	for _, op := range methodOps {
		methodOpTokens = append(methodOpTokens, op)
	}

	// sort by each token length (the longer, the earlier)
	sort.Slice(methodOpTokens, func(i, j int) bool {
		return len(methodOpTokens[i]) > len(methodOpTokens[j])
	})
	// NOTE: order is important!
	// in regex group with pipes, first match is selected (not the longest one!)
	// Therefore, a long token is never matched if there is a substring token
	// for that reason, sort methodOpTokens by token length
	// (e.g. : `'>>` should be tokenized [`'>>`], not [`'>`, `>`])

	// ident or private_ident or methodOps
	symbolable := fmt.Sprintf(`(%s|_+(%s)?|(%s))`,
		ident, ident, strings.Join(methodOpTokens, "|"))

	t := simplexer.NewRegexpTokenType

	// NOTE: order is important (the longer, the earlier)!
	// otherwise longer token is divided to shorter tokens unexpectedly
	// (e.g. : `>>` should be recognized one token (not `>` `>`))
	return []simplexer.TokenType{
		t(KWARG_IDENT, fmt.Sprintf(`\\(%s|_+(%s)?)`, ident, ident)),
		t(ARG_IDENT, `\\(0|[1-9][0-9]*)?`),
		t(EXP_FLOAT, `([0-9][0-9_]*[0-9]|[0-9]*)\.([0-9][0-9_]*[0-9]|[0-9]+)[eE]-?[0-9]+`),
		t(FLOAT, `([0-9][0-9_]*[0-9]|[0-9]*)\.([0-9][0-9_]*[0-9]|[0-9]+)`),
		t(HEX_INT, `0[xX]([0-9a-fA-F][0-9a-fA-F_]*[0-9a-fA-F]|[0-9a-fA-F]+)`),
		t(OCT_INT, `0[oO]([0-7][0-7_]*[0-7]|[0-7]+)`),
		t(BIN_INT, `0[bB]([01][01_]*[01]|[01]+)`),
		t(EXP_INT, `([0-9][0-9_]*[0-9]|[0-9]+)[eE]-?[0-9]+`),
		t(INT, `([0-9][0-9_]*[0-9]|[0-9]+)`),
		t(CHAR_STR, `\?(\\[snt\\]|[^\r\n\\])`),
		t(BACKQUOTE_STR, "`(\\\\`|[^`])*`"),
		t(HEAD_STR_PIECE, `"(\\\"|[^\"\n\r#])*#\{`),
		t(DOUBLEQUOTE_STR, `"(\\\"|[^\"\n\r])*"`),
		// NOTE: lexer deals with multiline chain
		// (if parser does, shift/reduce conflict occurs)
		t(MULTILINE_ADD_CHAIN, fmt.Sprintf(`%s[&~=]`, keepChainRet)),
		t(MULTILINE_MAIN_CHAIN, fmt.Sprintf(`%s[\.@$]`, keepChainRet)),
		// NOTE: comment(, which starts with "#") is included in RET
		// `#[^\n\r]*` is neseccery to lex final line comment (i.e. `#`)
		t(RET, ret),
		t(COMPOUND_ASSIGN, compoundAssign),
		t(SYMBOL, "'"+symbolable),
		t(SPACESHIP, methodOps["spaceship"]),
		t(ASSIGN, `:=`),
		t(RIGHT_ASSIGN, `=>`),
		t(DOUBLE_STAR, methodOps["doubleStar"]),
		t(DOUBLE_SLASH, methodOps["doubleSlash"]),
		t(BIT_LSHIFT, methodOps["bitLShift"]),
		t(BIT_RSHIFT, methodOps["bitRShift"]),
		t(TOPIC_EQ, methodOps["topicEq"]),
		t(TOPIC_NEQ, methodOps["topicNeq"]),
		t(EQ, methodOps["eq"]),
		t(NEQ, methodOps["neq"]),
		t(GE, methodOps["ge"]),
		t(LE, methodOps["le"]),
		t(AND, `&&`),
		t(OR, `\|\|`),
		t(BIT_AND, methodOps["bitAnd"]),
		t(BIT_OR, methodOps["bitOr"]),
		t(BIT_XOR, methodOps["bitXor"]),
		t(BIT_NOT, methodOps["bitNot"]),
		t(IADD, methodOps["iAdd"]),
		t(ISUB, methodOps["iSub"]),
		t(DIAMOND, `<>`),
		t(METHOD_LITER, `m<\{`),
		t(LITER, `<\{`),
		t(RITER, `\}>`),
		t(METHOD_MAP_LBRACE, `m%\{`),
		t(MAP_LBRACE, `%\{`),
		t(METHOD_LBRACE, `m\{`),
		t(LPAREN, `\(`),
		t(RPAREN, `\)`),
		t(VERT, `\|`),
		t(LBRACE, `\{`),
		t(RBRACE, `\}`),
		t(LBRACKET, `\[`),
		t(RBRACKET, `\]`),
		t(COMMA, `,`),
		t(COLON, `:`),
		t(SEMICOLON, `;`),
		t(CARET, `\^`),
		t(BANG, methodOps["bang"]),
		t(PLUS, methodOps["plus"]),
		t(MINUS, methodOps["minus"]),
		t(STAR, methodOps["star"]),
		t(SLASH, methodOps["slash"]),
		t(PERCENT, methodOps["percent"]),
		t(GT, methodOps["gt"]),
		t(LT, methodOps["lt"]),
		t(ADD_CHAIN, `[&~=]`),
		t(MAIN_CHAIN, `[\.@$]`),
		t(IF, `if`),
		t(ELSE, `else`),
		t(RETURN, `return`),
		t(YIELD, `yield`),
		t(RAISE, `raise`),
		t(DEFER, `defer`),
		t(IDENT, ident),
		t(PRIVATE_IDENT, fmt.Sprintf(`_+(%s)?`, ident)),
	}
}

func embeddedStrTokenTypes() []simplexer.TokenType {
	t := simplexer.NewRegexpTokenType

	// only used when parsing embeddedStr
	// (otherwise, func call like `{|x| x}("a")` is wrongly lexed to
	// TAIL_STR_PIECE)
	return []simplexer.TokenType{
		t(MID_STR_PIECE, `\}(\\\"|[^\"\n\r#])*#\{`),
		t(TAIL_STR_PIECE, `\}(\\\"|[^\"\n\r#])*"`),
	}
}

func NewLexer(reader io.Reader) *Lexer {
	l := simplexer.NewLexer(reader)
	l.TokenTypes = tokenTypes()
	// NOTE: remove "\n" from whitespace list
	// to use it stmts separator
	l.Whitespace = simplexer.NewPatternTokenType(
		-1, []string{" ", "\t"})
	return &Lexer{lexer: l}
}

func (l *Lexer) Lex(lval *yySymType) int {
	token, err := l.lexer.Scan()

	if _, ok := err.(*simplexer.UnknownTokenError); ok {
		l.Error(l.unknownTokenErrMsg())
	} else if err != nil {
		l.Error(l.ErrMsg())
	}

	if token == nil {
		return -1
	}

	if token.Type.GetID() == HEAD_STR_PIECE {
		// start embeddedStr lexing mode
		l.prependEmbeddedStrTokenTypes()
	}

	if token.Type.GetID() == TAIL_STR_PIECE {
		// finish embeddedStr lexing mode
		l.removeEmbeddedStrTokenTypes()
	}

	lval.token = token
	newSource := l.convertSourceInfo(token)
	// NOTE: fix Line string because Line refers next line
	// when token is at the end of the line.
	if l.Source != nil {
		if l.Source.Pos.Line == newSource.Pos.Line && l.Source.Line != newSource.Line {
			newSource.Line = l.Source.Line
		}
	}

	l.Source = newSource
	return int(token.Type.GetID())
}

func (l *Lexer) unknownTokenErrMsg() string {
	var out bytes.Buffer
	tok := l.Source.TokenLiteral
	if tok == "\n" {
		tok = "\\n" // for readability
	}

	out.WriteString(fmt.Sprintf("Lexer Error: unknown token '%s'was found\n",
		tok))
	out.WriteString("after " + l.Source.Pos.String() + "\n")
	out.WriteString(l.Source.Line + "\n")
	out.WriteString(fmt.Sprintf("in rule: %s\n", l.curRule))
	return out.String()
}

func (l *Lexer) ErrMsg() string {
	var out bytes.Buffer
	tok := l.Source.TokenLiteral
	if tok == "\n" {
		tok = "\\n" // for readability
	}

	out.WriteString(fmt.Sprintf("Lexer Error in token '%s':\n", tok))
	out.WriteString("after " + l.Source.Pos.String() + "\n")
	out.WriteString(l.Source.Line + "\n")
	out.WriteString(fmt.Sprintf("in rule: %s\n", l.curRule))
	return out.String()
}

func (l *Lexer) Error(e string) {
	// NOTE: yacc(yyParse) cannot return err object...
	panic(e)
}

func (l *Lexer) convertSourceInfo(token *simplexer.Token) *ast.Source {
	pos := ast.Position{
		Line:   token.Position.Line,
		Column: token.Position.Column,
	}
	return &ast.Source{
		Line:         l.lexer.GetLastLine(),
		Pos:          pos,
		TokenLiteral: token.Literal,
	}
}

func (l *Lexer) prependEmbeddedStrTokenTypes() {
	// additional tokentypes must prepend (not append) to other ones,
	// otherwise shorter token types (like `}` or `#`) are detected.
	l.lexer.TokenTypes = append(embeddedStrTokenTypes(), l.lexer.TokenTypes...)
}

func (l *Lexer) removeEmbeddedStrTokenTypes() {
	l.lexer.TokenTypes = tokenTypes()
}

//line yacctab:1
var yyExca = [...]int{
	-1, 1,
	1, -1,
	-2, 0,
}

const yyPrivate = 57344

const yyLast = 2531

var yyAct = [...]int{
	67, 188, 235, 160, 162, 164, 23, 232, 293, 109,
	166, 115, 83, 165, 2, 121, 122, 82, 54, 4,
	254, 31, 277, 344, 121, 122, 81, 80, 354, 342,
	116, 309, 349, 254, 303, 345, 47, 52, 48, 50,
	49, 53, 51, 65, 62, 63, 64, 66, 350, 130,
	163, 24, 25, 26, 254, 27, 265, 337, 237, 198,
	175, 157, 179, 179, 132, 197, 196, 177, 177, 338,
	195, 254, 28, 194, 170, 310, 193, 75, 76, 77,
	78, 43, 44, 45, 46, 22, 311, 192, 274, 68,
	173, 169, 74, 276, 168, 70, 71, 69, 72, 203,
	73, 60, 290, 254, 161, 287, 254, 200, 319, 202,
	117, 109, 109, 109, 109, 229, 254, 74, 291, 109,
	233, 288, 279, 236, 109, 109, 109, 109, 109, 254,
	254, 280, 270, 267, 157, 343, 254, 230, 254, 255,
	250, 275, 246, 248, 271, 268, 306, 306, 68, 157,
	157, 256, 247, 249, 254, 117, 69, 251, 306, 68,
	172, 306, 355, 182, 184, 170, 352, 69, 109, 252,
	254, 316, 313, 273, 304, 262, 236, 264, 260, 109,
	299, 176, 169, 266, 258, 357, 356, 353, 308, 332,
	109, 327, 109, 260, 159, 240, 201, 117, 317, 199,
	306, 305, 129, 128, 59, 109, 109, 109, 109, 109,
	109, 109, 109, 109, 109, 109, 109, 109, 109, 109,
	109, 109, 109, 109, 109, 109, 109, 109, 109, 109,
	282, 58, 284, 190, 55, 109, 35, 57, 56, 180,
	61, 79, 109, 131, 109, 109, 109, 41, 253, 257,
	114, 174, 43, 44, 45, 46, 119, 301, 302, 42,
	109, 187, 298, 269, 272, 157, 40, 157, 230, 39,
	230, 38, 37, 315, 302, 36, 281, 34, 8, 32,
	179, 33, 85, 321, 109, 318, 109, 30, 110, 111,
	112, 113, 331, 329, 29, 109, 236, 13, 109, 18,
	17, 118, 21, 123, 124, 125, 126, 127, 109, 75,
	76, 77, 78, 19, 20, 331, 16, 157, 15, 236,
	230, 289, 292, 109, 14, 109, 7, 109, 6, 5,
	1, 109, 0, 167, 109, 178, 109, 109, 0, 0,
	189, 109, 109, 0, 0, 191, 75, 76, 77, 78,
	0, 0, 109, 312, 0, 0, 0, 0, 0, 0,
	0, 0, 204, 205, 206, 207, 208, 209, 210, 211,
	212, 213, 214, 215, 216, 217, 218, 219, 220, 221,
	222, 223, 224, 225, 226, 227, 228, 0, 0, 0,
	339, 0, 0, 0, 0, 234, 0, 0, 0, 241,
	243, 244, 0, 0, 346, 0, 0, 0, 245, 85,
	90, 91, 86, 87, 0, 88, 89, 85, 292, 0,
	86, 87, 0, 88, 89, 0, 92, 93, 94, 95,
	96, 0, 0, 0, 0, 0, 75, 76, 77, 78,
	0, 0, 259, 0, 75, 76, 77, 78, 234, 0,
	0, 0, 47, 52, 48, 50, 49, 53, 51, 65,
	62, 63, 64, 66, 0, 241, 163, 24, 25, 26,
	0, 27, 0, 0, 0, 0, 0, 0, 0, 283,
	0, 285, 0, 0, 0, 0, 0, 0, 28, 0,
	170, 0, 0, 75, 76, 77, 78, 43, 44, 45,
	46, 22, 0, 0, 0, 68, 158, 169, 74, 0,
	168, 70, 71, 69, 72, 0, 73, 60, 294, 0,
	0, 297, 0, 0, 0, 9, 10, 11, 12, 0,
	0, 0, 178, 0, 0, 0, 0, 0, 0, 0,
	307, 0, 0, 0, 0, 0, 0, 0, 178, 0,
	0, 0, 85, 90, 91, 86, 87, 0, 88, 89,
	189, 322, 0, 324, 0, 326, 0, 0, 330, 92,
	93, 94, 333, 0, 335, 336, 0, 0, 0, 75,
	76, 77, 78, 0, 0, 340, 0, 341, 0, 0,
	0, 330, 47, 52, 48, 50, 49, 53, 51, 65,
	62, 63, 64, 66, 0, 0, 0, 24, 25, 26,
	0, 27, 0, 351, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 28, 0,
	170, 0, 0, 75, 76, 77, 78, 43, 44, 45,
	46, 22, 0, 0, 0, 68, 0, 169, 74, 0,
	0, 70, 71, 69, 72, 183, 73, 60, 0, 0,
	0, 0, 0, 0, 0, 9, 10, 11, 12, 47,
	52, 48, 50, 49, 53, 51, 65, 62, 63, 64,
	66, 0, 0, 0, 24, 25, 26, 0, 27, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 28, 0, 170, 0, 0,
	75, 76, 77, 78, 43, 44, 45, 46, 22, 0,
	0, 0, 68, 0, 169, 74, 0, 0, 70, 71,
	69, 72, 181, 73, 60, 0, 0, 0, 0, 0,
	0, 0, 9, 10, 11, 12, 47, 52, 48, 50,
	49, 53, 51, 65, 62, 63, 64, 66, 0, 0,
	0, 24, 25, 26, 0, 27, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 28, 0, 170, 0, 0, 75, 76, 77,
	78, 43, 44, 45, 46, 22, 0, 0, 0, 68,
	171, 169, 74, 0, 0, 70, 71, 69, 72, 0,
	73, 60, 0, 0, 0, 0, 0, 0, 0, 9,
	10, 11, 12, 47, 52, 48, 50, 49, 53, 51,
	65, 62, 63, 64, 66, 0, 0, 0, 24, 25,
	26, 0, 27, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 28,
	0, 170, 0, 0, 75, 76, 77, 78, 43, 44,
	45, 46, 22, 0, 0, 0, 68, 0, 169, 74,
	0, 0, 70, 71, 69, 72, 0, 73, 60, 0,
	0, 0, 0, 0, 0, 0, 9, 10, 11, 12,
	47, 52, 48, 50, 49, 53, 51, 65, 62, 63,
	64, 66, 0, 0, 0, 24, 25, 26, 0, 27,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 28, 0, 0, 0,
	0, 75, 76, 77, 78, 43, 44, 45, 46, 22,
	0, 0, 0, 68, 0, 0, 74, 0, 0, 70,
	71, 69, 72, 0, 73, 60, 3, 0, 0, 0,
	0, 0, 0, 9, 10, 11, 12, 47, 52, 48,
	50, 49, 53, 51, 65, 62, 63, 64, 66, 0,
	0, 0, 24, 25, 26, 0, 27, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 28, 0, 0, 0, 0, 75, 76,
	77, 78, 43, 44, 45, 46, 22, 0, 0, 0,
	68, 0, 0, 74, 0, 0, 70, 71, 69, 72,
	0, 73, 60, 0, 0, 0, 0, 0, 0, 0,
	9, 10, 11, 12, 47, 52, 48, 50, 49, 53,
	51, 65, 62, 63, 64, 66, 0, 0, 163, 24,
	25, 26, 0, 27, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	28, 0, 0, 0, 0, 75, 76, 77, 78, 43,
	44, 45, 46, 22, 0, 0, 0, 68, 314, 0,
	74, 0, 168, 70, 71, 69, 72, 0, 73, 60,
	47, 52, 48, 50, 49, 53, 51, 65, 62, 63,
	64, 66, 0, 0, 163, 24, 25, 26, 0, 27,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 28, 0, 0, 0,
	0, 75, 76, 77, 78, 43, 44, 45, 46, 22,
	0, 0, 0, 68, 300, 0, 74, 0, 168, 70,
	71, 69, 72, 0, 73, 60, 85, 90, 91, 86,
	87, 0, 88, 89, 97, 98, 99, 100, 101, 102,
	104, 103, 105, 92, 93, 94, 95, 96, 0, 106,
	107, 0, 0, 75, 76, 77, 78, 0, 0, 0,
	0, 0, 238, 0, 239, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 108, 84, 85, 90, 91, 86, 87, 0,
	88, 89, 97, 98, 99, 100, 101, 102, 104, 103,
	105, 92, 93, 94, 95, 96, 0, 106, 107, 0,
	0, 75, 76, 77, 78, 85, 90, 91, 86, 87,
	348, 88, 89, 97, 98, 99, 100, 101, 102, 104,
	103, 105, 92, 93, 94, 95, 96, 0, 106, 107,
	108, 84, 75, 76, 77, 78, 85, 90, 91, 86,
	87, 347, 88, 89, 97, 98, 99, 100, 101, 102,
	104, 103, 105, 92, 93, 94, 95, 96, 0, 106,
	107, 108, 84, 75, 76, 77, 78, 0, 0, 0,
	0, 0, 0, 0, 334, 0, 0, 0, 0, 0,
	47, 52, 48, 50, 49, 53, 51, 65, 62, 63,
	64, 66, 108, 84, 163, 24, 25, 26, 0, 27,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 28, 0, 0, 0,
	0, 75, 76, 77, 78, 43, 44, 45, 46, 22,
	328, 0, 0, 68, 0, 0, 74, 0, 0, 70,
	71, 69, 72, 0, 73, 60, 85, 90, 91, 86,
	87, 0, 88, 89, 97, 98, 99, 100, 101, 102,
	104, 103, 105, 92, 93, 94, 95, 96, 0, 106,
	107, 0, 0, 75, 76, 77, 78, 85, 90, 91,
	86, 87, 325, 88, 89, 97, 98, 99, 100, 101,
	102, 104, 103, 105, 92, 93, 94, 95, 96, 0,
	106, 107, 108, 84, 75, 76, 77, 78, 0, 0,
	0, 0, 0, 323, 0, 0, 0, 0, 0, 0,
	47, 52, 48, 50, 49, 53, 51, 65, 62, 63,
	64, 66, 0, 108, 84, 24, 25, 26, 0, 27,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 28, 0, 0, 0,
	0, 75, 76, 77, 78, 43, 44, 45, 46, 22,
	0, 0, 120, 68, 0, 0, 74, 320, 0, 70,
	71, 69, 72, 0, 73, 60, 85, 90, 91, 86,
	87, 0, 88, 89, 97, 98, 99, 100, 101, 102,
	104, 103, 105, 92, 93, 94, 95, 96, 0, 106,
	107, 0, 0, 75, 76, 77, 78, 0, 0, 0,
	0, 0, 0, 0, 296, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 108, 84, 85, 90, 91, 86, 87, 0,
	88, 89, 97, 98, 99, 100, 101, 102, 104, 103,
	105, 92, 93, 94, 95, 96, 0, 106, 107, 0,
	0, 75, 76, 77, 78, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	108, 0, 286, 85, 90, 91, 86, 87, 0, 88,
	89, 97, 98, 99, 100, 101, 102, 104, 103, 105,
	92, 93, 94, 95, 96, 0, 106, 107, 0, 0,
	75, 76, 77, 78, 0, 0, 0, 0, 0, 0,
	0, 239, 0, 0, 0, 0, 47, 52, 48, 50,
	49, 53, 51, 65, 62, 63, 64, 66, 0, 108,
	84, 24, 25, 26, 0, 27, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 28, 0, 0, 0, 0, 75, 76, 77,
	78, 43, 44, 45, 46, 22, 0, 0, 242, 68,
	0, 0, 74, 278, 0, 70, 71, 69, 72, 0,
	73, 60, 85, 90, 91, 86, 87, 0, 88, 89,
	97, 98, 99, 100, 101, 102, 104, 103, 105, 92,
	93, 94, 95, 96, 0, 106, 107, 0, 0, 75,
	76, 77, 78, 0, 0, 0, 0, 0, 0, 0,
	261, 0, 0, 0, 0, 0, 47, 52, 48, 50,
	49, 53, 51, 65, 62, 63, 64, 66, 108, 84,
	163, 24, 25, 26, 0, 27, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 28, 0, 0, 0, 0, 75, 76, 77,
	78, 43, 44, 45, 46, 22, 231, 0, 0, 68,
	0, 0, 74, 0, 0, 70, 71, 69, 72, 0,
	73, 60, 47, 52, 48, 50, 49, 53, 51, 65,
	62, 63, 64, 66, 0, 0, 0, 24, 25, 26,
	0, 27, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 28, 0,
	0, 0, 0, 75, 76, 77, 78, 43, 44, 45,
	46, 22, 0, 0, 186, 68, 0, 0, 74, 185,
	0, 70, 71, 69, 72, 0, 73, 60, 85, 90,
	91, 86, 87, 0, 88, 89, 97, 98, 99, 100,
	101, 102, 104, 103, 105, 92, 93, 94, 95, 96,
	0, 106, 107, 0, 0, 75, 76, 77, 78, 47,
	52, 48, 50, 49, 53, 51, 65, 62, 63, 64,
	66, 0, 0, 0, 24, 25, 26, 0, 27, 0,
	0, 0, 0, 0, 108, 84, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 28, 0, 0, 0, 0,
	75, 76, 77, 78, 43, 44, 45, 46, 22, 0,
	0, 295, 68, 0, 0, 74, 0, 0, 70, 71,
	69, 72, 0, 73, 60, 47, 52, 48, 50, 49,
	53, 51, 65, 62, 63, 64, 66, 0, 0, 0,
	24, 25, 26, 0, 27, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 28, 0, 0, 0, 0, 75, 76, 77, 78,
	43, 44, 45, 46, 22, 0, 0, 0, 68, 0,
	263, 74, 0, 0, 70, 71, 69, 72, 0, 73,
	60, 47, 52, 48, 50, 49, 53, 51, 65, 62,
	63, 64, 66, 0, 0, 0, 24, 25, 26, 0,
	27, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 28, 0, 0,
	0, 0, 75, 76, 77, 78, 43, 44, 45, 46,
	22, 0, 0, 242, 68, 0, 0, 74, 0, 0,
	70, 71, 69, 72, 0, 73, 60, 47, 52, 48,
	50, 49, 53, 51, 65, 62, 63, 64, 66, 0,
	0, 0, 24, 25, 26, 0, 27, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 28, 0, 0, 0, 0, 75, 76,
	77, 78, 43, 44, 45, 46, 22, 0, 0, 120,
	68, 0, 0, 74, 0, 0, 70, 71, 69, 72,
	0, 73, 60, 47, 52, 48, 50, 49, 53, 51,
	65, 62, 63, 64, 66, 0, 0, 0, 24, 25,
	26, 0, 27, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 28,
	0, 0, 0, 0, 75, 76, 77, 78, 43, 44,
	45, 46, 22, 0, 0, 0, 68, 0, 0, 74,
	0, 0, 70, 71, 69, 72, 0, 73, 60, 85,
	90, 91, 86, 87, 0, 88, 89, 97, 98, 99,
	100, 101, 102, 104, 103, 105, 92, 93, 94, 95,
	96, 0, 106, 107, 0, 0, 75, 76, 77, 78,
	0, 140, 134, 135, 136, 137, 154, 138, 139, 141,
	142, 143, 0, 0, 147, 145, 146, 144, 148, 149,
	150, 151, 152, 153, 0, 108, 155, 156, 0, 0,
	0, 0, 43, 44, 45, 46, 0, 0, 0, 0,
	68, 0, 0, 0, 0, 133, 0, 0, 69, 85,
	90, 91, 86, 87, 0, 88, 89, 97, 98, 99,
	100, 101, 102, 104, 103, 105, 92, 93, 94, 95,
	96, 0, 106, 107, 0, 0, 75, 76, 77, 78,
	85, 90, 91, 86, 87, 0, 88, 89, 97, 98,
	99, 100, 101, 102, 104, 103, 105, 92, 93, 94,
	95, 96, 0, 106, 0, 0, 0, 75, 76, 77,
	78, 85, 90, 91, 86, 87, 0, 88, 89, 97,
	98, 99, 100, 101, 102, 104, 103, 105, 92, 93,
	94, 95, 96, 0, 0, 0, 0, 0, 75, 76,
	77, 78, 85, 90, 91, 86, 87, 0, 88, 89,
	85, 90, 91, 86, 87, 0, 88, 89, 0, 92,
	93, 0, 0, 0, 0, 0, 0, 0, 0, 75,
	76, 77, 78, 0, 0, 0, 0, 75, 76, 77,
	78,
}

var yyPact = [...]int{
	896, -1000, -44, 973, -1000, -1000, -63, -1000, 1940, 2249,
	2249, 2249, 2249, 57, -1000, -1000, -1000, -1000, -1000, -1000,
	-1000, -1000, 2183, -57, 2249, 2249, 2249, 2249, 2249, -1000,
	-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,
	-1000, 186, 2333, -1000, -1000, -1000, -1000, -1000, -1000, -1000,
	-1000, -1000, -1000, -1000, 448, 742, 32, 123, 665, 588,
	-1000, 1888, -1000, -1000, -1000, -1000, 2249, -1000, 17, 6,
	3, 0, -4, -5, -11, 153, 144, 150, 144, 973,
	-1000, -1000, -44, 2249, 2249, 2249, 2249, 2249, 2249, 2249,
	2249, 2249, 2249, 2249, 2249, 2249, 2249, 2249, 2249, 2249,
	2249, 2249, 2249, 2249, 2249, 2249, 2249, 2249, 203, -1000,
	2301, 2301, 2301, 2301, -1000, 91, 1822, -12, 1168, 141,
	2117, 2249, 2249, -1000, -1000, -1000, -1000, -1000, -1000, 2249,
	102, 102, -1000, 203, -1000, -1000, -1000, -1000, -1000, -1000,
	-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,
	-1000, -1000, -1000, -1000, -1000, -1000, -1000, 819, -1000, 99,
	81, 126, -1000, 2249, 973, -44, -1000, 1764, 203, 2051,
	-14, -1000, 125, -1000, 75, 74, 115, -1000, 1764, 973,
	83, -1000, 26, -1000, -45, -1000, 1712, 61, -1000, 1655,
	-1000, 1940, -1000, -1000, -1000, -1000, -1000, -1000, -1000, 144,
	2249, 144, 2249, -1000, 1940, 1596, 301, 264, 264, 264,
	264, 399, 399, 2482, 2482, 2474, 534, 534, 391, 391,
	391, 391, 391, 391, 391, 391, 391, 2443, 2412, -1000,
	-1000, -1000, 51, 48, 1940, -1000, -48, -1000, -1000, 1985,
	-1000, 1538, 2249, 2381, 2381, 1940, 91, -1000, 91, -1000,
	144, -1000, 122, 1116, -36, -1000, 116, 143, -1000, 1940,
	-44, 2249, 132, -39, 16, -1000, -1000, -1000, 114, 1050,
	-1000, 113, 140, -1000, 123, -1000, -1000, -1000, -1000, -1000,
	47, 1486, 2249, 1429, 2249, 1398, 2249, -1000, 137, 1346,
	-1000, 135, 182, 2249, 1288, 2249, 2249, 1940, 91, -1000,
	-1000, -1, -1000, -1000, -1000, -1000, 2249, 1940, 2249, -1000,
	-41, 76, 2249, -1000, -1000, -35, -1000, -1000, -1000, -1000,
	-1000, -1000, 1257, -1000, 1226, -1000, 2301, -1000, -1000, -22,
	1940, -1000, -1000, 1940, 2249, 1940, 1940, -1000, 108, 129,
	1940, 1940, -1000, -42, -1000, 104, 128, -1000, -1000, -1000,
	131, 1940, -1000, -1000, -1000, -1000, -1000, -1000,
}

var yyPgo = [...]int{
	0, 330, 13, 19, 329, 328, 326, 278, 324, 318,
	316, 314, 313, 302, 300, 299, 297, 294, 287, 21,
	281, 279, 277, 236, 275, 272, 271, 269, 266, 233,
	1, 104, 10, 181, 2, 4, 194, 7, 11, 5,
	261, 3, 6, 0, 259, 247, 243, 241, 88, 18,
	30, 240, 238, 237, 234, 231, 204,
}

var yyR1 = [...]int{
	0, 1, 1, 1, 1, 2, 2, 2, 3, 3,
	3, 4, 6, 5, 5, 5, 5, 7, 7, 7,
	7, 7, 16, 16, 16, 16, 16, 16, 42, 42,
	42, 42, 15, 15, 15, 15, 15, 15, 15, 15,
	15, 15, 15, 15, 17, 17, 17, 17, 17, 18,
	18, 14, 14, 8, 8, 8, 8, 8, 8, 8,
	8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
	8, 8, 8, 8, 8, 8, 9, 9, 9, 9,
	9, 10, 10, 10, 13, 24, 24, 24, 24, 24,
	24, 24, 24, 24, 24, 25, 25, 25, 25, 25,
	25, 25, 25, 25, 25, 23, 23, 23, 23, 23,
	26, 26, 26, 27, 28, 29, 29, 29, 29, 29,
	29, 29, 12, 45, 45, 19, 19, 19, 20, 20,
	20, 20, 21, 21, 33, 33, 31, 31, 31, 32,
	22, 39, 39, 39, 39, 39, 39, 39, 39, 11,
	11, 11, 11, 11, 11, 11, 11, 11, 11, 44,
	44, 38, 38, 38, 38, 38, 38, 38, 38, 38,
	46, 46, 46, 46, 46, 46, 46, 46, 46, 46,
	46, 46, 46, 46, 46, 46, 46, 46, 46, 46,
	46, 46, 46, 43, 43, 43, 43, 43, 43, 43,
	43, 40, 40, 37, 37, 37, 37, 30, 30, 36,
	36, 41, 41, 34, 35, 35, 49, 49, 50, 50,
	51, 51, 53, 53, 52, 52, 54, 54, 55, 55,
	56, 56, 47, 47, 48, 48,
}

var yyR2 = [...]int{
	0, 1, 2, 1, 0, 1, 3, 2, 1, 1,
	1, 1, 3, 2, 2, 2, 2, 1, 1, 1,
	1, 1, 1, 1, 1, 1, 3, 1, 1, 1,
	1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
	1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
	1, 3, 5, 3, 3, 3, 3, 3, 3, 3,
	3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
	3, 3, 3, 3, 3, 3, 2, 2, 2, 2,
	2, 3, 3, 3, 2, 2, 3, 4, 4, 3,
	4, 4, 5, 6, 6, 2, 3, 4, 4, 3,
	4, 4, 5, 6, 6, 2, 3, 3, 4, 4,
	1, 1, 1, 1, 3, 5, 3, 4, 4, 2,
	2, 3, 2, 3, 2, 3, 2, 3, 2, 3,
	2, 3, 3, 3, 3, 1, 1, 1, 1, 2,
	1, 2, 1, 3, 4, 3, 2, 4, 5, 2,
	3, 3, 2, 3, 3, 2, 3, 4, 2, 2,
	1, 2, 3, 4, 4, 3, 4, 5, 6, 2,
	1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
	1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
	1, 1, 1, 2, 1, 4, 5, 2, 1, 4,
	5, 3, 1, 3, 3, 1, 1, 1, 1, 3,
	1, 4, 2, 3, 3, 4, 1, 2, 1, 2,
	1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
	1, 2, 1, 1, 1, 2,
}

var yyChk = [...]int{
	-1000, -1, -2, 70, -3, -4, -5, -6, -7, 77,
	78, 79, 80, -16, -8, -9, -10, -14, -15, -12,
	-11, -13, 53, -42, 19, 20, 21, 23, 40, -17,
	-18, -19, -21, -20, -22, -23, -24, -25, -26, -27,
	-28, -45, -44, 49, 50, 51, 52, 4, 6, 8,
	7, 10, 5, 9, -49, -54, -52, -53, -55, -56,
	69, -51, 12, 13, 14, 11, 15, -43, 57, 65,
	63, 64, 66, 68, 60, 45, 46, 47, 48, -47,
	71, 70, -2, 75, 75, 18, 21, 22, 24, 25,
	19, 20, 35, 36, 37, 38, 39, 26, 27, 28,
	29, 30, 31, 33, 32, 34, 41, 42, 74, -43,
	-7, -7, -7, -7, -23, -38, -50, 53, -7, -29,
	56, 72, 73, -7, -7, -7, -7, -7, 17, 16,
	-42, -46, -19, 62, 19, 20, 21, 22, 24, 25,
	18, 26, 27, 28, 34, 32, 33, 31, 35, 36,
	37, 38, 39, 40, 23, 43, 44, -49, 58, -36,
	-41, -31, -35, 18, -39, -2, -32, -7, 62, 59,
	42, 58, -31, 58, -36, -41, -33, -32, -7, -39,
	-33, 67, -31, 67, -31, 61, 56, -40, -30, -7,
	-29, -7, 70, 70, 70, 70, 70, 70, 70, 46,
	-50, 46, -50, -3, -7, -7, -7, -7, -7, -7,
	-7, -7, -7, -7, -7, -7, -7, -7, -7, -7,
	-7, -7, -7, -7, -7, -7, -7, -7, -7, -42,
	-19, 54, -37, -41, -7, -34, -42, 70, 54, 56,
	54, -7, 56, -7, -7, -7, -38, -19, -38, -19,
	-42, 58, 70, -48, 55, 58, 70, -48, 58, -7,
	-2, 56, -42, 59, -37, 70, 58, 58, 70, -48,
	58, 70, -48, 58, -48, 58, 67, 67, 61, 61,
	70, -48, -50, -7, -50, -7, 76, 54, 70, -48,
	54, 70, -48, 56, -7, 56, 56, -7, -38, 58,
	58, -41, -35, 70, 58, 58, 18, -7, 56, 70,
	59, 70, -48, 58, 58, -41, 58, 58, -32, 61,
	61, -30, -7, 54, -7, 54, -7, 54, 54, -41,
	-7, -34, 54, -7, 56, -7, -7, 58, 70, -48,
	-7, -7, 70, 59, 58, 70, -48, 54, 54, 54,
	70, -7, 58, 58, 70, 58, 58, 54,
}

var yyDef = [...]int{
	4, -2, 1, 3, 5, 8, 9, 10, 11, 0,
	0, 0, 0, 17, 18, 19, 20, 21, 22, 23,
	24, 25, 0, 27, 0, 0, 0, 0, 0, 32,
	33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
	43, 0, 0, 28, 29, 30, 31, 44, 45, 46,
	47, 48, 49, 50, 0, 0, 0, 0, 0, 0,
	140, 0, 110, 111, 112, 113, 0, 160, 216, 226,
	224, 222, 228, 230, 220, 0, 194, 0, 198, 7,
	232, 233, 2, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
	0, 0, 0, 0, 0, 0, 0, 0, 0, 159,
	13, 14, 15, 16, 84, 158, 0, 218, 0, 0,
	0, 0, 0, 76, 77, 78, 79, 80, 122, 0,
	149, 152, 155, 0, 170, 171, 172, 173, 174, 175,
	176, 177, 178, 179, 180, 181, 182, 183, 184, 185,
	186, 187, 188, 189, 190, 191, 192, 0, 85, 0,
	0, 0, 210, 0, 136, 137, 138, 11, 0, 0,
	142, 126, 0, 95, 0, 0, 0, 135, 0, 0,
	0, 128, 0, 130, 0, 105, 0, 0, 202, 207,
	208, 124, 217, 227, 225, 223, 229, 231, 221, 193,
	0, 197, 0, 6, 12, 51, 53, 54, 55, 56,
	57, 58, 59, 60, 61, 62, 63, 64, 65, 66,
	67, 68, 69, 70, 71, 72, 73, 74, 75, 83,
	169, 161, 0, 0, 205, 206, 27, 219, 26, 119,
	114, 120, 0, 81, 82, 123, 150, 151, 153, 154,
	156, 86, 0, 0, 234, 89, 0, 0, 125, 212,
	139, 0, 0, 141, 0, 146, 127, 96, 0, 0,
	99, 0, 0, 132, 0, 133, 129, 131, 106, 107,
	0, 0, 0, 0, 0, 0, 0, 162, 0, 0,
	165, 0, 0, 0, 116, 0, 0, 121, 157, 87,
	88, 0, 209, 235, 90, 91, 0, 214, 0, 145,
	143, 0, 0, 97, 98, 0, 100, 101, 134, 108,
	109, 201, 0, 195, 0, 199, 52, 163, 164, 0,
	203, 204, 166, 213, 0, 117, 118, 92, 0, 0,
	211, 215, 147, 144, 102, 0, 0, 196, 200, 167,
	0, 115, 93, 94, 148, 103, 104, 168,
}

var yyTok1 = [...]int{
	1,
}

var yyTok2 = [...]int{
	2, 3, 4, 5, 6, 7, 8, 9, 10, 11,
	12, 13, 14, 15, 16, 17, 18, 19, 20, 21,
	22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
	32, 33, 34, 35, 36, 37, 38, 39, 40, 41,
	42, 43, 44, 45, 46, 47, 48, 49, 50, 51,
	52, 53, 54, 55, 56, 57, 58, 59, 60, 61,
	62, 63, 64, 65, 66, 67, 68, 69, 70, 71,
	72, 73, 74, 75, 76, 77, 78, 79, 80, 81,
	82, 83, 84, 85, 86,
}

var yyTok3 = [...]int{
	0,
}

var yyErrorMessages = [...]struct {
	state int
	token int
	msg   string
}{}

//line yaccpar:1

/*	parser for yacc output	*/

var (
	yyDebug        = 0
	yyErrorVerbose = false
)

type yyLexer interface {
	Lex(lval *yySymType) int
	Error(s string)
}

type yyParser interface {
	Parse(yyLexer) int
	Lookahead() int
}

type yyParserImpl struct {
	lval  yySymType
	stack [yyInitialStackSize]yySymType
	char  int
}

func (p *yyParserImpl) Lookahead() int {
	return p.char
}

func yyNewParser() yyParser {
	return &yyParserImpl{}
}

const yyFlag = -1000

func yyTokname(c int) string {
	if c >= 1 && c-1 < len(yyToknames) {
		if yyToknames[c-1] != "" {
			return yyToknames[c-1]
		}
	}
	return __yyfmt__.Sprintf("tok-%v", c)
}

func yyStatname(s int) string {
	if s >= 0 && s < len(yyStatenames) {
		if yyStatenames[s] != "" {
			return yyStatenames[s]
		}
	}
	return __yyfmt__.Sprintf("state-%v", s)
}

func yyErrorMessage(state, lookAhead int) string {
	const TOKSTART = 4

	if !yyErrorVerbose {
		return "syntax error"
	}

	for _, e := range yyErrorMessages {
		if e.state == state && e.token == lookAhead {
			return "syntax error: " + e.msg
		}
	}

	res := "syntax error: unexpected " + yyTokname(lookAhead)

	// To match Bison, suggest at most four expected tokens.
	expected := make([]int, 0, 4)

	// Look for shiftable tokens.
	base := yyPact[state]
	for tok := TOKSTART; tok-1 < len(yyToknames); tok++ {
		if n := base + tok; n >= 0 && n < yyLast && yyChk[yyAct[n]] == tok {
			if len(expected) == cap(expected) {
				return res
			}
			expected = append(expected, tok)
		}
	}

	if yyDef[state] == -2 {
		i := 0
		for yyExca[i] != -1 || yyExca[i+1] != state {
			i += 2
		}

		// Look for tokens that we accept or reduce.
		for i += 2; yyExca[i] >= 0; i += 2 {
			tok := yyExca[i]
			if tok < TOKSTART || yyExca[i+1] == 0 {
				continue
			}
			if len(expected) == cap(expected) {
				return res
			}
			expected = append(expected, tok)
		}

		// If the default action is to accept or reduce, give up.
		if yyExca[i+1] != 0 {
			return res
		}
	}

	for i, tok := range expected {
		if i == 0 {
			res += ", expecting "
		} else {
			res += " or "
		}
		res += yyTokname(tok)
	}
	return res
}

func yylex1(lex yyLexer, lval *yySymType) (char, token int) {
	token = 0
	char = lex.Lex(lval)
	if char <= 0 {
		token = yyTok1[0]
		goto out
	}
	if char < len(yyTok1) {
		token = yyTok1[char]
		goto out
	}
	if char >= yyPrivate {
		if char < yyPrivate+len(yyTok2) {
			token = yyTok2[char-yyPrivate]
			goto out
		}
	}
	for i := 0; i < len(yyTok3); i += 2 {
		token = yyTok3[i+0]
		if token == char {
			token = yyTok3[i+1]
			goto out
		}
	}

out:
	if token == 0 {
		token = yyTok2[1] /* unknown char */
	}
	if yyDebug >= 3 {
		__yyfmt__.Printf("lex %s(%d)\n", yyTokname(token), uint(char))
	}
	return char, token
}

func yyParse(yylex yyLexer) int {
	return yyNewParser().Parse(yylex)
}

func (yyrcvr *yyParserImpl) Parse(yylex yyLexer) int {
	var yyn int
	var yyVAL yySymType
	var yyDollar []yySymType
	_ = yyDollar // silence set and not used
	yyS := yyrcvr.stack[:]

	Nerrs := 0   /* number of errors */
	Errflag := 0 /* error recovery flag */
	yystate := 0
	yyrcvr.char = -1
	yytoken := -1 // yyrcvr.char translated into internal numbering
	defer func() {
		// Make sure we report no lookahead when not parsing.
		yystate = -1
		yyrcvr.char = -1
		yytoken = -1
	}()
	yyp := -1
	goto yystack

ret0:
	return 0

ret1:
	return 1

yystack:
	/* put a state and value onto the stack */
	if yyDebug >= 4 {
		__yyfmt__.Printf("char %v in %v\n", yyTokname(yytoken), yyStatname(yystate))
	}

	yyp++
	if yyp >= len(yyS) {
		nyys := make([]yySymType, len(yyS)*2)
		copy(nyys, yyS)
		yyS = nyys
	}
	yyS[yyp] = yyVAL
	yyS[yyp].yys = yystate

yynewstate:
	yyn = yyPact[yystate]
	if yyn <= yyFlag {
		goto yydefault /* simple state */
	}
	if yyrcvr.char < 0 {
		yyrcvr.char, yytoken = yylex1(yylex, &yyrcvr.lval)
	}
	yyn += yytoken
	if yyn < 0 || yyn >= yyLast {
		goto yydefault
	}
	yyn = yyAct[yyn]
	if yyChk[yyn] == yytoken { /* valid shift */
		yyrcvr.char = -1
		yytoken = -1
		yyVAL = yyrcvr.lval
		yystate = yyn
		if Errflag > 0 {
			Errflag--
		}
		goto yystack
	}

yydefault:
	/* default state action */
	yyn = yyDef[yystate]
	if yyn == -2 {
		if yyrcvr.char < 0 {
			yyrcvr.char, yytoken = yylex1(yylex, &yyrcvr.lval)
		}

		/* look through exception table */
		xi := 0
		for {
			if yyExca[xi+0] == -1 && yyExca[xi+1] == yystate {
				break
			}
			xi += 2
		}
		for xi += 2; ; xi += 2 {
			yyn = yyExca[xi+0]
			if yyn < 0 || yyn == yytoken {
				break
			}
		}
		yyn = yyExca[xi+1]
		if yyn < 0 {
			goto ret0
		}
	}
	if yyn == 0 {
		/* error ... attempt to resume parsing */
		switch Errflag {
		case 0: /* brand new error */
			yylex.Error(yyErrorMessage(yystate, yytoken))
			Nerrs++
			if yyDebug >= 1 {
				__yyfmt__.Printf("%s", yyStatname(yystate))
				__yyfmt__.Printf(" saw %s\n", yyTokname(yytoken))
			}
			fallthrough

		case 1, 2: /* incompletely recovered error ... try again */
			Errflag = 3

			/* find a state where "error" is a legal shift action */
			for yyp >= 0 {
				yyn = yyPact[yyS[yyp].yys] + yyErrCode
				if yyn >= 0 && yyn < yyLast {
					yystate = yyAct[yyn] /* simulate a shift of "error" */
					if yyChk[yystate] == yyErrCode {
						goto yystack
					}
				}

				/* the current p has no shift on "error", pop stack */
				if yyDebug >= 2 {
					__yyfmt__.Printf("error recovery pops state %d\n", yyS[yyp].yys)
				}
				yyp--
			}
			/* there is no state on the stack with an error shift ... abort */
			goto ret1

		case 3: /* no shift yet; clobber input char */
			if yyDebug >= 2 {
				__yyfmt__.Printf("error recovery discards %s\n", yyTokname(yytoken))
			}
			if yytoken == yyEofCode {
				goto ret1
			}
			yyrcvr.char = -1
			yytoken = -1
			goto yynewstate /* try again in the same state */
		}
	}

	/* reduction by production yyn */
	if yyDebug >= 2 {
		__yyfmt__.Printf("reduce %v in:\n\t%v\n", yyn, yyStatname(yystate))
	}

	yynt := yyn
	yypt := yyp
	_ = yypt // guard against "declared and not used"

	yyp -= yyR2[yyn]
	// yyp is now the index of $0. Perform the default action. Iff the
	// reduced production is Îµ, $1 is possibly out of range.
	if yyp+1 >= len(yyS) {
		nyys := make([]yySymType, len(yyS)*2)
		copy(nyys, yyS)
		yyS = nyys
	}
	yyVAL = yyS[yyp+1]

	/* consult goto table to find next state */
	yyn = yyR1[yyn]
	yyg := yyPgo[yyn]
	yyj := yyg + yyS[yyp].yys + 1

	if yyj >= yyLast {
		yystate = yyAct[yyg]
	} else {
		yystate = yyAct[yyj]
		if yyChk[yystate] != -yyn {
			yystate = yyAct[yyg]
		}
	}
	// dummy call; replaced with literal code
	switch yynt {

	case 1:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:109
		{
			yyVAL.program = &ast.Program{Stmts: yyDollar[1].stmts}
			yylex.(*Lexer).program = yyVAL.program
			yylex.(*Lexer).curRule = "program -> stmts"
		}
	case 2:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:115
		{
			yyVAL.program = &ast.Program{Stmts: yyDollar[2].stmts}
			yylex.(*Lexer).program = yyVAL.program
			yylex.(*Lexer).curRule = "program -> RET stmts"
		}
	case 3:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:121
		{
			yyVAL.program = &ast.Program{Stmts: []ast.Stmt{}}
			yylex.(*Lexer).program = yyVAL.program
			yylex.(*Lexer).curRule = "program -> RET"
		}
	case 4:
		yyDollar = yyS[yypt-0 : yypt+1]
//line ./parser/parser.go.y:127
		{
			yyVAL.program = &ast.Program{Stmts: []ast.Stmt{}}
			yylex.(*Lexer).program = yyVAL.program
			yylex.(*Lexer).curRule = "program -> (nothing)"
		}
	case 5:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:135
		{
			yyVAL.stmts = []ast.Stmt{yyDollar[1].stmt}
			yylex.(*Lexer).curRule = "stmts -> stmt"
		}
	case 6:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:140
		{
			yyVAL.stmts = append(yyDollar[1].stmts, yyDollar[3].stmt)
			yylex.(*Lexer).curRule = "stmts -> stmts breakLine stmt"
		}
	case 7:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:145
		{
			yyVAL.stmts = yyDollar[1].stmts
			yylex.(*Lexer).curRule = "stmts -> stmts breakLine"
		}
	case 8:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:152
		{
			yyVAL.stmt = yyDollar[1].stmt
			yylex.(*Lexer).curRule = "stmt -> exprStmt"
		}
	case 9:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:157
		{
			yyVAL.stmt = yyDollar[1].stmt
			yylex.(*Lexer).curRule = "stmt -> jumpStmt"
		}
	case 10:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:162
		{
			yyVAL.stmt = yyDollar[1].stmt
			yylex.(*Lexer).curRule = "stmt -> jumpIfStmt"
		}
	case 11:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:169
		{
			yyVAL.stmt = &ast.ExprStmt{
				Token: "(exprStmt)",
				Expr:  yyDollar[1].expr,
				Src:   yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "exprStmt -> expr"
		}
	case 12:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:180
		{
			yyVAL.stmt = &ast.JumpIfStmt{
				JumpStmt: yyDollar[1].stmt.(*ast.JumpStmt),
				Cond:     yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 13:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:190
		{
			yyVAL.stmt = &ast.JumpStmt{
				Token:    yyDollar[1].token.Literal,
				Val:      yyDollar[2].expr,
				JumpType: ast.ReturnJump,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 14:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:199
		{
			yyVAL.stmt = &ast.JumpStmt{
				Token:    yyDollar[1].token.Literal,
				Val:      yyDollar[2].expr,
				JumpType: ast.RaiseJump,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 15:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:208
		{
			yyVAL.stmt = &ast.JumpStmt{
				Token:    yyDollar[1].token.Literal,
				Val:      yyDollar[2].expr,
				JumpType: ast.YieldJump,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 16:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:217
		{
			yyVAL.stmt = &ast.JumpStmt{
				Token:    yyDollar[1].token.Literal,
				Val:      yyDollar[2].expr,
				JumpType: ast.DeferJump,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 17:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:228
		{
			yyVAL.expr = yyDollar[1].expr
			yylex.(*Lexer).curRule = "expr -> unitExpr"
		}
	case 18:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:233
		{
			yyVAL.expr = yyDollar[1].expr
			yylex.(*Lexer).curRule = "expr -> infixExpr"
		}
	case 19:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:238
		{
			yyVAL.expr = yyDollar[1].expr
			yylex.(*Lexer).curRule = "expr -> prefixExpr"
		}
	case 20:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:243
		{
			yyVAL.expr = yyDollar[1].expr
			yylex.(*Lexer).curRule = "expr -> assignExpr"
		}
	case 21:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:248
		{
			yyVAL.expr = yyDollar[1].expr
			yylex.(*Lexer).curRule = "expr -> ifExpr"
		}
	case 22:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:255
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 23:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:259
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 24:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:263
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 25:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:267
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 26:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:271
		{
			yyVAL.expr = yyDollar[2].expr
		}
	case 27:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:275
		{
			yyVAL.expr = yyDollar[1].ident
		}
	case 28:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:281
		{
			yyVAL.ident = &ast.Ident{
				Token:     yyDollar[1].token.Literal,
				Value:     yyDollar[1].token.Literal,
				Src:       yylex.(*Lexer).Source,
				IsPrivate: false,
				IdentAttr: ast.NormalIdent,
			}
			yylex.(*Lexer).curRule = "ident -> IDENT"
		}
	case 29:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:292
		{
			yyVAL.ident = &ast.Ident{
				Token:     yyDollar[1].token.Literal,
				Value:     yyDollar[1].token.Literal,
				Src:       yylex.(*Lexer).Source,
				IsPrivate: true,
				IdentAttr: ast.NormalIdent,
			}
			yylex.(*Lexer).curRule = "ident -> PRIVATE_IDENT"
		}
	case 30:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:303
		{
			yyVAL.ident = &ast.Ident{
				Token:     yyDollar[1].token.Literal,
				Value:     yyDollar[1].token.Literal,
				Src:       yylex.(*Lexer).Source,
				IsPrivate: true,
				IdentAttr: ast.ArgIdent,
			}
			yylex.(*Lexer).curRule = "ident -> ARG_IDENT"
		}
	case 31:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:314
		{
			yyVAL.ident = &ast.Ident{
				Token:     yyDollar[1].token.Literal,
				Value:     yyDollar[1].token.Literal,
				Src:       yylex.(*Lexer).Source,
				IsPrivate: true,
				IdentAttr: ast.KwargIdent,
			}
			yylex.(*Lexer).curRule = "ident -> KWARG_IDENT"
		}
	case 32:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:327
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 33:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:331
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 34:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:335
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 35:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:339
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 36:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:343
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 37:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:347
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 38:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:351
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 39:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:355
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 40:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:359
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 41:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:363
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 42:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:367
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 43:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:371
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 44:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:377
		{
			// remove separator "_"s
			intStr := strings.Replace(yyDollar[1].token.Literal, "_", "", -1)
			n, _ := strconv.ParseInt(intStr, 10, 64)
			yyVAL.expr = &ast.IntLiteral{
				Token: yyDollar[1].token.Literal,
				Value: n,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 45:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:388
		{
			// remove separator "_"s
			lit := strings.Replace(yyDollar[1].token.Literal, "_", "", -1)
			// remove prefix "0x"
			intStr := lit[2:]
			n, _ := strconv.ParseInt(intStr, 16, 64)
			yyVAL.expr = &ast.IntLiteral{
				Token: yyDollar[1].token.Literal,
				Value: n,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 46:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:401
		{
			// remove separator "_"s
			lit := strings.Replace(yyDollar[1].token.Literal, "_", "", -1)
			// remove prefix "0o"
			intStr := lit[2:]
			n, _ := strconv.ParseInt(intStr, 8, 64)
			yyVAL.expr = &ast.IntLiteral{
				Token: yyDollar[1].token.Literal,
				Value: n,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 47:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:414
		{
			// remove separator "_"s
			lit := strings.Replace(yyDollar[1].token.Literal, "_", "", -1)
			// remove prefix "0b"
			intStr := lit[2:]
			n, _ := strconv.ParseInt(intStr, 2, 64)
			yyVAL.expr = &ast.IntLiteral{
				Token: yyDollar[1].token.Literal,
				Value: n,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 48:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:427
		{
			// remove separator "_"s
			lit := strings.Replace(yyDollar[1].token.Literal, "_", "", -1)
			// NOTE: ToLower is nesessary (to split by both e and E)
			toks := strings.Split(strings.ToLower(lit), "e")
			// NOTE: cast float to deal with minus exp (i.e. `100e-2 == 1`)
			val, _ := strconv.ParseFloat(toks[0], 64)
			// NOTE: cannot use ParseInt (math.Pow requires float)
			exp, _ := strconv.ParseFloat(toks[1], 64)
			yyVAL.expr = &ast.IntLiteral{
				Token: yyDollar[1].token.Literal,
				Value: int64(val * math.Pow(10, exp)),
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 49:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:445
		{
			// remove separator "_"s
			floatStr := strings.Replace(yyDollar[1].token.Literal, "_", "", -1)
			n, _ := strconv.ParseFloat(floatStr, 64)
			yyVAL.expr = &ast.FloatLiteral{
				Token: yyDollar[1].token.Literal,
				Value: n,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 50:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:456
		{
			// remove separator "_"s
			lit := strings.Replace(yyDollar[1].token.Literal, "_", "", -1)
			// NOTE: ToLower is nesessary (to split by both e and E)
			toks := strings.Split(strings.ToLower(lit), "e")
			val, _ := strconv.ParseFloat(toks[0], 64)
			exp, _ := strconv.ParseFloat(toks[1], 64)
			yyVAL.expr = &ast.FloatLiteral{
				Token: yyDollar[1].token.Literal,
				Value: float64(val * math.Pow(10, exp)),
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 51:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:472
		{
			yyVAL.expr = &ast.IfExpr{
				Token: yyDollar[2].token.Literal,
				Cond:  yyDollar[3].expr,
				Then:  yyDollar[1].expr,
				Else:  nil,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 52:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:482
		{
			// NOTE: to refrain shift/reduce conflict, else has higher prec than if
			// `a if b if c else d` means `((a if b) if c else d)`
			yyVAL.expr = &ast.IfExpr{
				Token: yyDollar[2].token.Literal,
				Cond:  yyDollar[3].expr,
				Then:  yyDollar[1].expr,
				Else:  yyDollar[5].expr,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 53:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:496
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr DOUBLE_STAR expr"
		}
	case 54:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:507
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr STAR expr"
		}
	case 55:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:518
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr SLASH expr"
		}
	case 56:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:529
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr DOUBLE_SLASH expr"
		}
	case 57:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:540
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr PERCENT expr"
		}
	case 58:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:551
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr PLUS expr"
		}
	case 59:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:562
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr MINUS expr"
		}
	case 60:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:573
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr BIT_LSHIFT expr"
		}
	case 61:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:584
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr BIT_RSHIFT expr"
		}
	case 62:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:595
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr BIT_AND expr"
		}
	case 63:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:606
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr BIT_OR expr"
		}
	case 64:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:617
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr BIT_XOR expr"
		}
	case 65:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:628
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr SPACESHIP expr"
		}
	case 66:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:639
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr EQ expr"
		}
	case 67:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:650
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr NEQ expr"
		}
	case 68:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:661
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr TOPIC_EQ expr"
		}
	case 69:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:672
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr TOPIC_NEQ expr"
		}
	case 70:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:683
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr LT expr"
		}
	case 71:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:694
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr GT expr"
		}
	case 72:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:705
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr LE expr"
		}
	case 73:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:716
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr GE expr"
		}
	case 74:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:727
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr AND expr"
		}
	case 75:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:738
		{
			yyVAL.expr = &ast.InfixExpr{
				Token:    yyDollar[2].token.Literal,
				Left:     yyDollar[1].expr,
				Operator: yyDollar[2].token.Literal,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "infixExpr -> expr OR expr"
		}
	case 76:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:751
		{
			yyVAL.expr = &ast.PrefixExpr{
				Token:    yyDollar[1].token.Literal,
				Operator: yyDollar[1].token.Literal,
				Right:    yyDollar[2].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "prefixExpr -> PLUS expr"
		}
	case 77:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:761
		{
			// HACK: convert -(number) to literal
			// TOFIX: deal with this process in lexer
			switch r := yyDollar[2].expr.(type) {
			case *ast.IntLiteral:
				yyVAL.expr = &ast.IntLiteral{
					Token: "-" + r.Token,
					Value: -r.Value,
					Src:   yylex.(*Lexer).Source,
				}
			case *ast.FloatLiteral:
				yyVAL.expr = &ast.FloatLiteral{
					Token: "-" + r.Token,
					Value: -r.Value,
					Src:   yylex.(*Lexer).Source,
				}
			default:
				yyVAL.expr = &ast.PrefixExpr{
					Token:    yyDollar[1].token.Literal,
					Operator: yyDollar[1].token.Literal,
					Right:    yyDollar[2].expr,
					Src:      yylex.(*Lexer).Source,
				}
			}
		}
	case 78:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:787
		{
			yyVAL.expr = &ast.PrefixExpr{
				Token:    yyDollar[1].token.Literal,
				Operator: yyDollar[1].token.Literal,
				Right:    yyDollar[2].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "prefixExpr -> STAR expr"
		}
	case 79:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:797
		{
			yyVAL.expr = &ast.PrefixExpr{
				Token:    yyDollar[1].token.Literal,
				Operator: yyDollar[1].token.Literal,
				Right:    yyDollar[2].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "prefixExpr -> BANG expr"
		}
	case 80:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:807
		{
			yyVAL.expr = &ast.PrefixExpr{
				Token:    yyDollar[1].token.Literal,
				Operator: yyDollar[1].token.Literal,
				Right:    yyDollar[2].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "prefixExpr -> BIT_NOT expr"
		}
	case 81:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:819
		{
			yyVAL.expr = &ast.AssignExpr{
				Token: yyDollar[2].token.Literal,
				Left:  yyDollar[1].ident,
				Right: yyDollar[3].expr,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 82:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:828
		{
			op := yyDollar[2].token.Literal[:len(yyDollar[2].token.Literal)-1]
			ie := &ast.InfixExpr{
				Token:    op,
				Left:     yyDollar[1].ident,
				Operator: op,
				Right:    yyDollar[3].expr,
				Src:      yylex.(*Lexer).Source,
			}
			yyVAL.expr = &ast.AssignExpr{
				Token: ":=",
				Left:  yyDollar[1].ident,
				Right: ie,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 83:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:845
		{
			// NOTE: "Left" and "Right" are reversed!
			yyVAL.expr = &ast.AssignExpr{
				Token: ":=",
				Left:  yyDollar[3].ident,
				Right: yyDollar[1].expr,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 84:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:857
		{
			atIdent := &ast.Ident{
				Token:     "at",
				Value:     "at",
				Src:       yylex.(*Lexer).Source,
				IsPrivate: false,
				IdentAttr: ast.NormalIdent,
			}
			yyVAL.expr = &ast.PropCallExpr{
				Token:    yyDollar[1].expr.TokenLiteral(),
				Chain:    ast.MakeChain("", ".", nil),
				Receiver: yyDollar[1].expr,
				Prop:     atIdent,
				Args:     []ast.Expr{yyDollar[2].expr},
				Kwargs:   map[*ast.Ident]ast.Expr{},
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 85:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:878
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 86:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:887
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 87:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:896
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 88:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:905
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 89:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:914
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: yyDollar[2].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 90:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:923
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: yyDollar[2].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 91:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:932
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: yyDollar[2].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 92:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:941
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: yyDollar[4].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 93:
		yyDollar = yyS[yypt-6 : yypt+1]
//line ./parser/parser.go.y:950
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: yyDollar[4].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 94:
		yyDollar = yyS[yypt-6 : yypt+1]
//line ./parser/parser.go.y:959
		{
			yyVAL.expr = &ast.ObjLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: yyDollar[4].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 95:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:970
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 96:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:979
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 97:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:988
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 98:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:997
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: []ast.Expr{},
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 99:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1006
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: yyDollar[2].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 100:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1015
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: yyDollar[2].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 101:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1024
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         []*ast.Pair{},
				EmbeddedExprs: yyDollar[2].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 102:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:1033
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: yyDollar[4].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 103:
		yyDollar = yyS[yypt-6 : yypt+1]
//line ./parser/parser.go.y:1042
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: yyDollar[4].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 104:
		yyDollar = yyS[yypt-6 : yypt+1]
//line ./parser/parser.go.y:1051
		{
			yyVAL.expr = &ast.MapLiteral{
				Token:         yyDollar[1].token.Literal,
				Pairs:         yyDollar[2].pairList,
				EmbeddedExprs: yyDollar[4].exprList,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 105:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1062
		{
			yyVAL.expr = &ast.ArrLiteral{
				Token: yyDollar[1].token.Literal,
				Elems: []ast.Expr{},
				Src:   yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "arrLiteral -> lBracket RBRACKET"
		}
	case 106:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1072
		{
			emptyRange := &ast.RangeLiteral{
				Token: yyDollar[2].token.Literal,
				Start: nil,
				Stop:  nil,
				Step:  nil,
				Src:   yylex.(*Lexer).Source,
			}

			yyVAL.expr = &ast.ArrLiteral{
				Token: yyDollar[1].token.Literal,
				Elems: []ast.Expr{emptyRange},
				Src:   yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "arrLiteral -> lBracket RBRACKET"
		}
	case 107:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1090
		{
			yyVAL.expr = &ast.ArrLiteral{
				Token: yyDollar[1].token.Literal,
				Elems: yyDollar[2].exprList,
				Src:   yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "arrLiteral -> lBracket exprList RBRACKET"
		}
	case 108:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1100
		{
			yyVAL.expr = &ast.ArrLiteral{
				Token: yyDollar[1].token.Literal,
				Elems: yyDollar[2].exprList,
				Src:   yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "arrLiteral -> lBracket exprList RBRACKET"
		}
	case 109:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1110
		{
			yyVAL.expr = &ast.ArrLiteral{
				Token: yyDollar[1].token.Literal,
				Elems: yyDollar[2].exprList,
				Src:   yylex.(*Lexer).Source,
			}
			yylex.(*Lexer).curRule = "arrLiteral -> lBracket exprList RBRACKET"
		}
	case 110:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1122
		{
			yyVAL.expr = &ast.StrLiteral{
				Token: yyDollar[1].token.Literal,
				Value: yyDollar[1].token.Literal[1:],
				IsRaw: false,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 111:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1131
		{
			str := yyDollar[1].token.Literal[1 : len(yyDollar[1].token.Literal)-1]
			// replace escaped backquotes with backquotes
			str = strings.Replace(str, "\\`", "`", -1)

			yyVAL.expr = &ast.StrLiteral{
				Token: yyDollar[1].token.Literal,
				Value: str,
				IsRaw: true,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 112:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1144
		{
			// unquote escape sequences here
			// NOTE: backquotes are unwraped in Unquote
			unquoted, _ := strconv.Unquote(yyDollar[1].token.Literal)
			yyVAL.expr = &ast.StrLiteral{
				Token: yyDollar[1].token.Literal,
				Value: unquoted,
				IsRaw: false,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 113:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1158
		{
			yyVAL.expr = &ast.SymLiteral{
				Token: yyDollar[1].token.Literal,
				Value: yyDollar[1].token.Literal[1:],
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 114:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1168
		{
			yyVAL.expr = yyDollar[2].expr
		}
	case 115:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:1174
		{
			yyVAL.expr = &ast.RangeLiteral{
				Token: yyDollar[2].token.Literal,
				Start: yyDollar[1].expr,
				Stop:  yyDollar[3].expr,
				Step:  yyDollar[5].expr,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 116:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1184
		{
			yyVAL.expr = &ast.RangeLiteral{
				Token: yyDollar[2].token.Literal,
				Start: yyDollar[1].expr,
				Stop:  yyDollar[3].expr,
				Step:  nil,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 117:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1194
		{
			yyVAL.expr = &ast.RangeLiteral{
				Token: yyDollar[2].token.Literal,
				Start: yyDollar[1].expr,
				Stop:  nil,
				Step:  yyDollar[4].expr,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 118:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1204
		{
			yyVAL.expr = &ast.RangeLiteral{
				Token: yyDollar[1].token.Literal,
				Start: nil,
				Stop:  yyDollar[2].expr,
				Step:  yyDollar[4].expr,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 119:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1214
		{
			yyVAL.expr = &ast.RangeLiteral{
				Token: yyDollar[2].token.Literal,
				Start: yyDollar[1].expr,
				Stop:  nil,
				Step:  nil,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 120:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1224
		{
			yyVAL.expr = &ast.RangeLiteral{
				Token: yyDollar[1].token.Literal,
				Start: nil,
				Stop:  yyDollar[2].expr,
				Step:  nil,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 121:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1234
		{
			yyVAL.expr = &ast.RangeLiteral{
				Token: yyDollar[1].token.Literal,
				Start: nil,
				Stop:  nil,
				Step:  yyDollar[3].expr,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 122:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1246
		{
			// unquote escape sequences here
			// NOTE: doublequotes are unwraped in Unquote
			unquoted, _ := strconv.Unquote("\"" + yyDollar[2].token.Literal[1:])
			yyVAL.expr = &ast.EmbeddedStr{
				Token:  yyDollar[1].formerStrPiece.Token,
				Former: yyDollar[1].formerStrPiece,
				Latter: unquoted,
				Src:    yylex.(*Lexer).Source,
			}
		}
	case 123:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1260
		{
			// unquote escape sequences here
			// NOTE: doublequotes are unwraped in Unquote
			unquoted, _ := strconv.Unquote("\"" + yyDollar[2].token.Literal[1:len(yyDollar[2].token.Literal)-2] + "\"")
			yyVAL.formerStrPiece = &ast.FormerStrPiece{
				Token:  yyDollar[1].formerStrPiece.Token,
				Former: yyDollar[1].formerStrPiece,
				Str:    unquoted,
				Expr:   yyDollar[3].expr,
			}
		}
	case 124:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1272
		{
			// unquote escape sequences here
			// NOTE: doublequotes are unwraped in Unquote
			unquoted, _ := strconv.Unquote(yyDollar[1].token.Literal[:len(yyDollar[1].token.Literal)-2] + "\"")
			yyVAL.formerStrPiece = &ast.FormerStrPiece{
				Token:  yyDollar[1].token.Literal,
				Former: nil,
				Str:    unquoted,
				Expr:   yyDollar[2].expr,
			}
		}
	case 125:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1286
		{
			yyVAL.expr = &ast.FuncLiteral{
				Token:         yyDollar[1].token.Literal,
				FuncComponent: yyDollar[2].funcComponent,
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 126:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1294
		{
			yyVAL.expr = &ast.FuncLiteral{
				Token: yyDollar[1].token.Literal,
				Src:   yylex.(*Lexer).Source,
				FuncComponent: ast.FuncComponent{
					Args:   ast.SelfIdentArgList(yylex.(*Lexer).Source).Args,
					Kwargs: map[*ast.Ident]ast.Expr{},
					Body:   []ast.Stmt{},
					Src:    yylex.(*Lexer).Source,
				},
			}
		}
	case 127:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1307
		{
			yyVAL.expr = &ast.FuncLiteral{
				Token:         yyDollar[1].token.Literal,
				FuncComponent: *yyDollar[2].funcComponent.PrependSelf(yylex.(*Lexer).Source),
				Src:           yylex.(*Lexer).Source,
			}
		}
	case 128:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1317
		{
			yyVAL.expr = &ast.IterLiteral{
				Token: yyDollar[1].token.Literal,
				Src:   yylex.(*Lexer).Source,
				FuncComponent: ast.FuncComponent{
					Args:   []ast.Expr{},
					Kwargs: map[*ast.Ident]ast.Expr{},
					Body:   []ast.Stmt{},
					Src:    yylex.(*Lexer).Source,
				},
			}
		}
	case 129:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1330
		{
			yyVAL.expr = &ast.IterLiteral{
				Token:         yyDollar[1].token.Literal,
				Src:           yylex.(*Lexer).Source,
				FuncComponent: yyDollar[2].funcComponent,
			}
		}
	case 130:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1338
		{
			yyVAL.expr = &ast.IterLiteral{
				Token: yyDollar[1].token.Literal,
				Src:   yylex.(*Lexer).Source,
				FuncComponent: ast.FuncComponent{
					Args:   ast.SelfIdentArgList(yylex.(*Lexer).Source).Args,
					Kwargs: map[*ast.Ident]ast.Expr{},
					Body:   []ast.Stmt{},
					Src:    yylex.(*Lexer).Source,
				},
			}
		}
	case 131:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1351
		{
			yyVAL.expr = &ast.IterLiteral{
				Token:         yyDollar[1].token.Literal,
				Src:           yylex.(*Lexer).Source,
				FuncComponent: *yyDollar[2].funcComponent.PrependSelf(yylex.(*Lexer).Source),
			}
		}
	case 132:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1361
		{
			yyVAL.expr = &ast.MatchLiteral{
				Token:    yyDollar[1].token.Literal,
				Patterns: yyDollar[2].funcComponentList,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 133:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1369
		{
			patterns := []*ast.FuncComponent{}
			for _, p := range yyDollar[2].funcComponentList {
				patterns = append(patterns, p.PrependSelf(yylex.(*Lexer).Source))
			}

			yyVAL.expr = &ast.MatchLiteral{
				Token:    yyDollar[1].token.Literal,
				Patterns: patterns,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 134:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1384
		{
			// NOTE: assigning is nesessary because $3 is passed by reference
			// which means address of $3 is the last match of funcComponentList
			// (same as for loop)
			comp := yyDollar[3].funcComponent
			yyVAL.funcComponentList = append(yyDollar[1].funcComponentList, &comp)
		}
	case 135:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1392
		{
			comp := yyDollar[1].funcComponent
			yyVAL.funcComponentList = []*ast.FuncComponent{&comp}
		}
	case 136:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1399
		{
			yyVAL.funcComponent = ast.FuncComponent{
				Args:   yyDollar[1].argList.Args,
				Kwargs: yyDollar[1].argList.Kwargs,
				Body:   []ast.Stmt{},
				Src:    yylex.(*Lexer).Source,
			}
		}
	case 137:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1408
		{
			yyVAL.funcComponent = ast.FuncComponent{
				Args:   []ast.Expr{},
				Kwargs: map[*ast.Ident]ast.Expr{},
				Body:   yyDollar[1].stmts,
				Src:    yylex.(*Lexer).Source,
			}
		}
	case 138:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1417
		{
			yyVAL.funcComponent = yyDollar[1].funcComponent
		}
	case 139:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1423
		{
			yyVAL.funcComponent = ast.FuncComponent{
				Args:   yyDollar[1].argList.Args,
				Kwargs: yyDollar[1].argList.Kwargs,
				Body:   yyDollar[2].stmts,
				Src:    yylex.(*Lexer).Source,
			}
		}
	case 140:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1434
		{
			yyVAL.expr = &ast.DiamondLiteral{
				Token: yyDollar[1].token.Literal,
				Src:   yylex.(*Lexer).Source,
			}
		}
	case 141:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1443
		{
			yyVAL.argList = &ast.ArgList{
				Args:   []ast.Expr{},
				Kwargs: map[*ast.Ident]ast.Expr{},
			}
		}
	case 142:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1450
		{
			yyVAL.argList = &ast.ArgList{
				Args:   []ast.Expr{},
				Kwargs: map[*ast.Ident]ast.Expr{},
			}
		}
	case 143:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1457
		{
			yyVAL.argList = yyDollar[2].argList
		}
	case 144:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1461
		{
			yyVAL.argList = yyDollar[2].argList
		}
	case 145:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1465
		{
			yyVAL.argList = &ast.ArgList{
				Args:   []ast.Expr{},
				Kwargs: map[*ast.Ident]ast.Expr{},
			}
		}
	case 146:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1472
		{
			yyVAL.argList = &ast.ArgList{
				Args:   []ast.Expr{},
				Kwargs: map[*ast.Ident]ast.Expr{},
			}
		}
	case 147:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1479
		{
			yyVAL.argList = yyDollar[2].argList
		}
	case 148:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:1483
		{
			yyVAL.argList = yyDollar[2].argList
		}
	case 149:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1489
		{
			yyVAL.expr = &ast.PropCallExpr{
				Token:    "(propCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Prop:     yyDollar[2].ident,
				Args:     []ast.Expr{},
				Kwargs:   map[*ast.Ident]ast.Expr{},
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 150:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1501
		{
			yyVAL.expr = &ast.PropCallExpr{
				Token:    "(propCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Prop:     yyDollar[2].ident,
				Args:     yyDollar[3].argList.Args,
				Kwargs:   yyDollar[3].argList.Kwargs,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 151:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1513
		{
			yyVAL.expr = &ast.PropCallExpr{
				Token:    "(propCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Prop:     yyDollar[2].ident,
				Args:     []ast.Expr{yyDollar[3].expr},
				Kwargs:   map[*ast.Ident]ast.Expr{},
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 152:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1525
		{
			opIdent := &ast.Ident{
				Token:     yyDollar[2].token.Literal,
				Value:     yyDollar[2].token.Literal,
				Src:       yylex.(*Lexer).Source,
				IsPrivate: true,
			}
			yyVAL.expr = &ast.PropCallExpr{
				Token:    "(propCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Prop:     opIdent,
				Args:     []ast.Expr{},
				Kwargs:   map[*ast.Ident]ast.Expr{},
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 153:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1543
		{
			opIdent := &ast.Ident{
				Token:     yyDollar[2].token.Literal,
				Value:     yyDollar[2].token.Literal,
				Src:       yylex.(*Lexer).Source,
				IsPrivate: true,
			}
			yyVAL.expr = &ast.PropCallExpr{
				Token:    "(propCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Prop:     opIdent,
				Args:     yyDollar[3].argList.Args,
				Kwargs:   yyDollar[3].argList.Kwargs,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 154:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1561
		{
			opIdent := &ast.Ident{
				Token:     yyDollar[2].token.Literal,
				Value:     yyDollar[2].token.Literal,
				Src:       yylex.(*Lexer).Source,
				IsPrivate: true,
			}
			yyVAL.expr = &ast.PropCallExpr{
				Token:    "(propCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Prop:     opIdent,
				Args:     []ast.Expr{yyDollar[3].expr},
				Kwargs:   map[*ast.Ident]ast.Expr{},
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 155:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1579
		{
			yyVAL.expr = &ast.LiteralCallExpr{
				Token:    "(literalCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Func:     yyDollar[2].expr.(*ast.FuncLiteral),
				Args:     []ast.Expr{},
				Kwargs:   map[*ast.Ident]ast.Expr{},
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 156:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1591
		{
			yyVAL.expr = &ast.VarCallExpr{
				Token:    "(varCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Var:      yyDollar[3].ident,
				Args:     []ast.Expr{},
				Kwargs:   map[*ast.Ident]ast.Expr{},
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 157:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1603
		{
			yyVAL.expr = &ast.VarCallExpr{
				Token:    "(varCall)",
				Chain:    yyDollar[1].recvAndChain.Chain,
				Receiver: yyDollar[1].recvAndChain.Recv,
				Var:      yyDollar[3].ident,
				Args:     yyDollar[4].argList.Args,
				Kwargs:   yyDollar[4].argList.Kwargs,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 158:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1615
		{
			callIdent := &ast.Ident{
				Token:     "call",
				Value:     "call",
				Src:       yylex.(*Lexer).Source,
				IsPrivate: false,
				IdentAttr: ast.NormalIdent,
			}
			yyVAL.expr = &ast.PropCallExpr{
				Token:    "(propCall)",
				Chain:    ast.MakeChain("", ".", nil),
				Receiver: yyDollar[1].expr,
				Prop:     callIdent,
				Args:     yyDollar[2].argList.Args,
				Kwargs:   yyDollar[2].argList.Kwargs,
				Src:      yylex.(*Lexer).Source,
			}
		}
	case 159:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1636
		{
			yyVAL.recvAndChain = &ast.RecvAndChain{
				Recv:  yyDollar[1].expr,
				Chain: yyDollar[2].chain,
			}
		}
	case 160:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1643
		{
			yyVAL.recvAndChain = &ast.RecvAndChain{
				Recv:  nil,
				Chain: yyDollar[1].chain,
			}
		}
	case 161:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1652
		{
			yyVAL.argList = &ast.ArgList{
				Args:   []ast.Expr{},
				Kwargs: map[*ast.Ident]ast.Expr{},
			}
			yylex.(*Lexer).curRule = "callArgs -> lParen RPAREN"
		}
	case 162:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1660
		{
			yyVAL.argList = yyDollar[2].argList
			yylex.(*Lexer).curRule = "callArgs -> lParen argList RPAREN"
		}
	case 163:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1665
		{
			yyVAL.argList = yyDollar[2].argList
			yylex.(*Lexer).curRule = "callArgs -> lParen argList RET RPAREN"
		}
	case 164:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1670
		{
			yyVAL.argList = yyDollar[2].argList
			yylex.(*Lexer).curRule = "callArgs -> lParen argList comma RPAREN"
		}
	case 165:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1675
		{
			expansionList := []ast.Expr{}
			for _, exp := range yyDollar[2].exprList {
				prefixExpr := &ast.PrefixExpr{
					Token:    "**",
					Operator: "**",
					Right:    exp,
					Src:      yylex.(*Lexer).Source,
				}
				expansionList = append(expansionList, prefixExpr)
			}

			argList := ast.ExprToArgList(expansionList[0])
			for _, e := range expansionList[1:] {
				argList.AppendArg(e)
			}
			yyVAL.argList = argList
			yylex.(*Lexer).curRule = "callArgs -> lParen kwargExpansionList RPAREN"
		}
	case 166:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1695
		{
			expansionList := []ast.Expr{}
			for _, exp := range yyDollar[2].exprList {
				prefixExpr := &ast.PrefixExpr{
					Token:    "**",
					Operator: "**",
					Right:    exp,
					Src:      yylex.(*Lexer).Source,
				}
				expansionList = append(expansionList, prefixExpr)
			}

			argList := ast.ExprToArgList(expansionList[0])
			for _, e := range expansionList[1:] {
				argList.AppendArg(e)
			}
			yyVAL.argList = argList
			yylex.(*Lexer).curRule = "callArgs -> lParen kwargExpansionList RET RPAREN"
		}
	case 167:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:1715
		{
			argList := yyDollar[2].argList
			for _, exp := range yyDollar[4].exprList {
				prefixExpr := &ast.PrefixExpr{
					Token:    "**",
					Operator: "**",
					Right:    exp,
					Src:      yylex.(*Lexer).Source,
				}
				argList.AppendArg(prefixExpr)
			}
			yyVAL.argList = argList
			yylex.(*Lexer).curRule = "callArgs -> lParen kwargExpansionList RPAREN"
		}
	case 168:
		yyDollar = yyS[yypt-6 : yypt+1]
//line ./parser/parser.go.y:1730
		{
			argList := yyDollar[2].argList
			for _, exp := range yyDollar[4].exprList {
				prefixExpr := &ast.PrefixExpr{
					Token:    "**",
					Operator: "**",
					Right:    exp,
					Src:      yylex.(*Lexer).Source,
				}
				argList.AppendArg(prefixExpr)
			}
			yyVAL.argList = argList
			yylex.(*Lexer).curRule = "callArgs -> lParen argList kwargExpansionList RET RPAREN"
		}
	case 169:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1745
		{
			yyVAL.argList = yyDollar[1].argList.AppendArg(yyDollar[2].expr)
			yylex.(*Lexer).curRule = "callArgs -> callArgs funcLiteral"
		}
	case 170:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1752
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> PLUS"
		}
	case 171:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1757
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> MINUS"
		}
	case 172:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1762
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> STAR"
		}
	case 173:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1767
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> SLASH"
		}
	case 174:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1772
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> DOUBLE_SLASH"
		}
	case 175:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1777
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> PERCENT"
		}
	case 176:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1782
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> DOUBLE_STAR"
		}
	case 177:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1787
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> SPACESHIP"
		}
	case 178:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1792
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> EQ"
		}
	case 179:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1797
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> NEQ"
		}
	case 180:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1802
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> GE"
		}
	case 181:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1807
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> LE"
		}
	case 182:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1812
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> GT"
		}
	case 183:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1817
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> LT"
		}
	case 184:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1822
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> BIT_LSHIFT"
		}
	case 185:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1827
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> BIT_RSHIFT"
		}
	case 186:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1832
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> BIT_AND"
		}
	case 187:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1837
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> BIT_OR"
		}
	case 188:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1842
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> BIT_XOR"
		}
	case 189:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1847
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> BIT_NOT"
		}
	case 190:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1852
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> BANG"
		}
	case 191:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1857
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> IADD"
		}
	case 192:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1862
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "opMethod -> ISUB"
		}
	case 193:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1869
		{
			yyVAL.chain = ast.MakeChain(yyDollar[1].token.Literal, yyDollar[2].token.Literal, nil)
			yylex.(*Lexer).curRule = "chain -> ADD_CHAIN MAIN_CHAIN"
		}
	case 194:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1874
		{
			yyVAL.chain = ast.MakeChain("", yyDollar[1].token.Literal, nil)
			yylex.(*Lexer).curRule = "chain -> MAIN_CHAIN"
		}
	case 195:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1879
		{
			yyVAL.chain = ast.MakeChain("", yyDollar[1].token.Literal, yyDollar[3].expr)
			yylex.(*Lexer).curRule = "chain -> MAIN_CHAIN lParen expr RPAREN"
		}
	case 196:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:1884
		{
			yyVAL.chain = ast.MakeChain(yyDollar[1].token.Literal, yyDollar[2].token.Literal, yyDollar[4].expr)
			yylex.(*Lexer).curRule = "chain -> ADD_CHAIN MAIN_CHAIN lParen expr RPAREN"
		}
	case 197:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1889
		{
			ac := string(yyDollar[1].token.Literal[len(yyDollar[1].token.Literal)-1])
			yyVAL.chain = ast.MakeChain(ac, yyDollar[2].token.Literal, nil)
		}
	case 198:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1894
		{
			mc := string(yyDollar[1].token.Literal[len(yyDollar[1].token.Literal)-1])
			yyVAL.chain = ast.MakeChain("", mc, nil)
		}
	case 199:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1899
		{
			mc := string(yyDollar[1].token.Literal[len(yyDollar[1].token.Literal)-1])
			yyVAL.chain = ast.MakeChain("", mc, yyDollar[3].expr)
		}
	case 200:
		yyDollar = yyS[yypt-5 : yypt+1]
//line ./parser/parser.go.y:1904
		{
			ac := string(yyDollar[1].token.Literal[len(yyDollar[1].token.Literal)-1])
			yyVAL.chain = ast.MakeChain(ac, yyDollar[2].token.Literal, yyDollar[4].expr)
		}
	case 201:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1911
		{
			yyVAL.exprList = append(yyDollar[1].exprList, yyDollar[3].expr)
		}
	case 202:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1915
		{
			yyVAL.exprList = []ast.Expr{yyDollar[1].expr}
			yylex.(*Lexer).curRule = "exprList -> expr"
		}
	case 203:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1922
		{
			yyVAL.argList = yyDollar[1].argList.AppendArg(yyDollar[3].expr)
			yylex.(*Lexer).curRule = "argList -> argList comma expr"
		}
	case 204:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1927
		{
			yyVAL.argList = yyDollar[1].argList.AppendKwarg(yyDollar[3].kwargPair.Key, yyDollar[3].kwargPair.Val)
			yylex.(*Lexer).curRule = "argList -> argList comma pair"
		}
	case 205:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1932
		{
			yyVAL.argList = ast.ExprToArgList(yyDollar[1].expr)
			yylex.(*Lexer).curRule = "argList -> expr"
		}
	case 206:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1937
		{
			yyVAL.argList = ast.KwargPairToArgList(yyDollar[1].kwargPair)
			yylex.(*Lexer).curRule = "argList -> pair"
		}
	case 207:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1944
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 208:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1948
		{
			yyVAL.expr = yyDollar[1].expr
		}
	case 209:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1954
		{
			yyVAL.pairList = append(yyDollar[1].pairList, yyDollar[3].pair)
		}
	case 210:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1958
		{
			yyVAL.pairList = []*ast.Pair{yyDollar[1].pair}
		}
	case 211:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1964
		{
			yyVAL.exprList = append(yyDollar[1].exprList, yyDollar[4].expr)
		}
	case 212:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1968
		{
			yyVAL.exprList = []ast.Expr{yyDollar[2].expr}
		}
	case 213:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1974
		{
			yyVAL.kwargPair = &ast.KwargPair{Key: yyDollar[1].ident, Val: yyDollar[3].expr}
			yylex.(*Lexer).curRule = "kwargPair -> ident COLON expr"
		}
	case 214:
		yyDollar = yyS[yypt-3 : yypt+1]
//line ./parser/parser.go.y:1981
		{
			yyVAL.pair = &ast.Pair{Key: yyDollar[1].expr, Val: yyDollar[3].expr}
		}
	case 215:
		yyDollar = yyS[yypt-4 : yypt+1]
//line ./parser/parser.go.y:1985
		{
			pinned := &ast.PinnedIdent{Ident: *yyDollar[2].ident}
			yyVAL.pair = &ast.Pair{Key: pinned, Val: yyDollar[4].expr}
		}
	case 216:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:1992
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "lBrace -> LBRACE RET"
		}
	case 217:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:1997
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "lBrace -> LBRACE RET"
		}
	case 218:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2004
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "lParen -> LPAREN"
		}
	case 219:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2009
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "lParen -> LPAREN RET"
		}
	case 220:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2016
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "lBracket -> LBRACKET"
		}
	case 221:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2021
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "lBracket -> LBRACKET RET"
		}
	case 222:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2028
		{
			yyVAL.token = yyDollar[1].token
		}
	case 223:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2032
		{
			yyVAL.token = yyDollar[1].token
		}
	case 224:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2038
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "mapLBrace -> MAP_LBRACE"
		}
	case 225:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2043
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "mapLBrace -> MAP_LBRACE RET"
		}
	case 226:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2050
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "mapLBrace -> METHOD_LBRACE"
		}
	case 227:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2055
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "mapLBrace -> METHOD_LBRACE RET"
		}
	case 228:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2062
		{
			yyVAL.token = yyDollar[1].token
		}
	case 229:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2066
		{
			yyVAL.token = yyDollar[1].token
		}
	case 230:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2072
		{
			yyVAL.token = yyDollar[1].token
		}
	case 231:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2076
		{
			yyVAL.token = yyDollar[1].token
		}
	case 232:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2082
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "breakLine -> SEMICOLON"
		}
	case 233:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2087
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "breakLine -> RET"
		}
	case 234:
		yyDollar = yyS[yypt-1 : yypt+1]
//line ./parser/parser.go.y:2094
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "comma -> COMMA"
		}
	case 235:
		yyDollar = yyS[yypt-2 : yypt+1]
//line ./parser/parser.go.y:2099
		{
			yyVAL.token = yyDollar[1].token
			yylex.(*Lexer).curRule = "comma -> COMMA RET"
		}
	}
	goto yystack /* stack new state and value */
}
